{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c27f15",
   "metadata": {},
   "source": [
    "Converting rtf to docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60c4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "from docx import Document\n",
    "import zipfile\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e93dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_rtf_to_docx(input_file, output_file):\n",
    "    try:\n",
    "        # Convert RTF to DOCX\n",
    "        pypandoc.convert_file(input_file, 'docx', outputfile=output_file)\n",
    "        print(f\"Conversion successful: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548db6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_xml_from_docx(docx_path, xml_filename):\n",
    "    with zipfile.ZipFile(docx_path, 'r') as docx_zip:\n",
    "        if xml_filename in docx_zip.namelist():\n",
    "            xml_content = docx_zip.read(xml_filename)\n",
    "            return etree.XML(xml_content)\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c69ea",
   "metadata": {},
   "source": [
    "Execution starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7779283",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_process(rtf_path, output_docx_file, text_output_file, namespaces):\n",
    "    convert_rtf_to_docx(rtf_path,output_docx_file)\n",
    "    tree = extract_xml_from_docx(output_docx_file, 'word/document.xml')\n",
    "    #save the xml content to a file\n",
    "    if tree is not None:\n",
    "        with open(text_output_file, 'wb') as f:\n",
    "            f.write(etree.tostring(tree, pretty_print=True, xml_declaration=True, encoding='UTF-8'))\n",
    "        print(f\"XML content saved to {text_output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded3e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xml.dom.minidom import parseString\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def pretty_print_xml(input_file_path, output_file_path):\n",
    "    # Read the XML content from the text file\n",
    "    with open(input_file_path, 'r') as file:\n",
    "        xml_content = file.read()\n",
    "\n",
    "    # Parse the XML content\n",
    "    dom = parseString(xml_content)\n",
    "\n",
    "    # Pretty print the XML with indentation\n",
    "    pretty_xml_as_string = dom.toprettyxml(indent=\"  \")\n",
    "\n",
    "    # Write the pretty printed XML to the output file\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write(pretty_xml_as_string)\n",
    "\n",
    "# Example usage\n",
    "input_file = r'NYLB\\NYLB32revisioncopy.txt'  # Path to your input text file containing XML\n",
    "output_file = 'vendor_output_32.xml'  # Path to save the pretty printed XML file\n",
    "\n",
    "pretty_print_xml(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28856672",
   "metadata": {},
   "outputs": [],
   "source": [
    "namespaces = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}\n",
    "rtf_path= 'NYLB/NYLB 32 (revision copy).rtf'\n",
    "output_docx_file = rtf_path.replace('.rtf', '.docx')\n",
    "text_output_file = \"text_\" + output_docx_file.split('/')[-1].replace('.docx', '.txt')\n",
    "\n",
    "main_process(rtf_path, output_docx_file,text_output_file,namespaces)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3a91c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PyRTF\n",
    "from PyRTF import parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc59b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyrtf.parser import RtfParser\n",
    "from PyRTF.Elements import Document, Text\n",
    "import PyRTF\n",
    "import xml.etree.ElementTree as ET\n",
    "#import parser\n",
    "from PyRTF.parser import RtfParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1090830",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_field_codes_from_rtf(rtf_path):\n",
    "    # Read the RTF file\n",
    "    with open(rtf_path, 'r') as file:\n",
    "        rtf_content = file.read()\n",
    "    \n",
    "    # Parse the RTF content\n",
    "    # parser = PyRTF.parser()\n",
    "    parser = parser.RtfParser()\n",
    "    doc = Document()\n",
    "    parser.parse(rtf_content, doc)\n",
    "    \n",
    "    field_codes = []\n",
    "\n",
    "    # Iterate through the text elements to find field codes\n",
    "    for element in doc.content:\n",
    "        if isinstance(element, Text):\n",
    "            # Assuming field codes have a specific pattern in your RTF\n",
    "            if element.text.startswith('FIELD'):\n",
    "                field_codes.append(element.text)\n",
    "    \n",
    "    return field_codes\n",
    "\n",
    "def field_codes_to_xml(field_codes):\n",
    "    # Create the root XML element\n",
    "    root = ET.Element(\"FieldCodes\")\n",
    "\n",
    "    # Add each field code as a child element\n",
    "    for code in field_codes:\n",
    "        field_element = ET.SubElement(root, \"FieldCode\")\n",
    "        field_element.text = code\n",
    "\n",
    "    # Return the XML string\n",
    "    return ET.tostring(root, encoding='unicode')\n",
    "\n",
    "def main():\n",
    "    rtf_path = r'NYLB/NYLB 32 (revision copy).rtf'  # Replace with your RTF document path\n",
    "    field_codes = extract_field_codes_from_rtf(rtf_path)\n",
    "    xml_data = field_codes_to_xml(field_codes)\n",
    "\n",
    "    # Print or save the XML data\n",
    "    print(xml_data)\n",
    "    with open('field_codes.xml', 'w') as xml_file:\n",
    "        xml_file.write(xml_data)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ae778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def clean_rtf_text(text):\n",
    "    \"\"\"Remove RTF formatting codes from text.\"\"\"\n",
    "    return re.sub(r'\\\\[a-zA-Z]+\\d*\\s*|[{}]', '', text).strip()\n",
    "\n",
    "def extract_rtf_fields_to_xml(rtf_file_path, xml_output_path):\n",
    "    \"\"\"Extract fields from an RTF file and save them as XML.\"\"\"\n",
    "    try:\n",
    "        with open(rtf_file_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            rtf_content = file.read()\n",
    "\n",
    "        # print(f\"Processing RTF file: {rtf_file_path} {rtf_content}\")\n",
    "        # Pattern to match fields with optional results\n",
    "        field_pattern = r'\\\\field\\s*\\{[^}]*\\\\fldinst\\s*\\{([^}]*)\\}[^}]*(?:\\\\fldrslt\\s*\\{([^}]*)\\})?[^}]*\\}'\n",
    "                    # r'(\\\\field\\s*\\{[^}]*\\\\fldinst\\s*\\{[^}]*\\}[^}]*\\\\fldrslt\\s*\\{[^}]*\\}[^}]*\\})'\n",
    "        matches = re.findall(field_pattern, rtf_content, re.IGNORECASE | re.DOTALL)\n",
    "        print(\"MAtches found:\", matches)\n",
    "        # Create XML structure\n",
    "        root = ET.Element('RTFFields')\n",
    "        for i, (instruction, result) in enumerate(matches):\n",
    "            field_element = ET.SubElement(root, 'Field', id=str(i + 1))\n",
    "\n",
    "            # Add instruction\n",
    "            inst_element = ET.SubElement(field_element, 'Instruction')\n",
    "            inst_element.text = clean_rtf_text(instruction)\n",
    "\n",
    "            # Add result if available\n",
    "            if result:\n",
    "                result_element = ET.SubElement(field_element, 'Result')\n",
    "                result_element.text = clean_rtf_text(result)\n",
    "\n",
    "        # Write XML to file\n",
    "        tree = ET.ElementTree(root)\n",
    "        tree.write(xml_output_path, encoding='utf-8', xml_declaration=True)\n",
    "\n",
    "        print(f\"Extracted {len(matches)} fields from '{rtf_file_path}' to '{xml_output_path}'\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: RTF file '{rtf_file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "def main():\n",
    "    # HARDCODED VALUES - Change these as needed\n",
    "    RTF_FILE_PATH = 'NYLB/NYLB 32 (revision copy).rtf'\n",
    "    XML_OUTPUT_PATH = 'fields_output.xml'\n",
    "\n",
    "    extract_rtf_fields_to_xml(RTF_FILE_PATH, XML_OUTPUT_PATH)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Running simple RTF field extraction...\")\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483c4853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_rtf_and_enclose_fields(rtf_content):\n",
    "    # Regular expression to match RTF field codes\n",
    "    field_code_pattern = r'\\\\field\\s*\\{[^}]*\\\\fldinst\\s*\\{([^}]*)\\}[^}]*(?:\\\\fldrslt\\s*\\{([^}]*)\\})?[^}]*\\}'\n",
    "    \n",
    "    # Find all field codes using regex\n",
    "    field_codes = re.findall(field_code_pattern, rtf_content, re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "    # Replace field codes with <field> tags, preserving spacing\n",
    "    for instruction, result in field_codes:\n",
    "        rtf_content = rtf_content.replace(instruction, f'<field>{instruction}</field>')\n",
    "\n",
    "    # Preserve paragraph, line, and section breaks\n",
    "    rtf_content = re.sub(r'\\\\pard', '', rtf_content)  # Paragraph breaks\n",
    "    rtf_content = re.sub(r'\\\\par ', '--para--', rtf_content)  # Paragraph breaks\n",
    "\n",
    "    rtf_content = re.sub(r'\\\\linex0', '', rtf_content)  # Line breaks\n",
    "    rtf_content = re.sub(r'\\\\line', '\\n', rtf_content)  # Line breaks\n",
    "    rtf_content = re.sub(r'\\\\sectdefaultcl', '', rtf_content)  # Section breaks\n",
    "    rtf_content = re.sub(r'\\\\sectd', '', rtf_content)\n",
    "    # rtf_content = re.sub(r'\\\\sect', '\\n--- Section Break ---\\n', rtf_content)  # Section breaks\n",
    "    # rtf_content = re.sub(r'\\\\tab', '--tab--', rtf_content)  # Section breaks\n",
    "    \n",
    "\n",
    "    # Remove all other RTF control words except field codes and preserve spacing\n",
    "    cleaned_content = re.sub(r'\\\\[a-z]+(\\d+)?(\\s+)?', '', rtf_content)  # Remove RTF control words except breaks\n",
    "    cleaned_content = re.sub(r'\\{|\\}', '', cleaned_content)  # Remove braces, except for field codes\n",
    "    # cleaned_content = re.sub(r'--para--', '', cleaned_content) \n",
    "    cleaned_content = re.sub(r'\\\\\\'3f', '', cleaned_content)  # Replace tab markers with actual tabs\n",
    "    # cleaned_content = re.sub(r'\\\\\\*', '', cleaned_content)  # Replace tab markers with actual tabs\n",
    "    cleaned_content = re.sub(r'(<field.*?>)(\\s*<field.*?>)+', \"<field>\" , cleaned_content)\n",
    "    cleaned_content = re.sub(r'(</field.*?>)(\\s*</field.*?>)+', \"</field>\" , cleaned_content)\n",
    "    \n",
    "    return cleaned_content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab6375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_junk_content(content):\n",
    "    # Remove all content above <?phoenix\n",
    "    content = re.sub(r'^.*?(?=<\\?phoenix)', '', content, flags=re.DOTALL)\n",
    "\n",
    "    # Remove all content after {\\*\\themedata} and closing bracket\n",
    "    content = re.sub(r'{\\\\\\*\\\\themedata[\\s\\S]*$', '', content, flags=re.DOTALL)\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db0e27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a542cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def enclose_tags(content):\n",
    "#     #para tags\n",
    "#     content = re.sub(r'(\\\\par\\s*)', r'<para>\\1</para>', content)\n",
    "#     content = re.sub(r'(\\\\pard\\s*)', r'<para>\\1</para>', content)\n",
    "    \n",
    "#     return content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c13ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "RTF_FILE_PATH = 'NYLB/NYLB 32 (revision copy).rtf'\n",
    "\n",
    "with open(RTF_FILE_PATH, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    rtf_content = file.read()\n",
    "    clean_rtf_content = clean_junk_content(rtf_content)\n",
    "    cleaned_rtf = clean_rtf_and_enclose_fields(clean_rtf_content)\n",
    "    # code_content = retain_field_codes(clean_rtf_content)\n",
    "    # modified_content = enclose_tags(code_content)\n",
    "\n",
    "    with open('cleaned_file.txt', 'w') as cleaned_file:\n",
    "        cleaned_file.write(cleaned_rtf)\n",
    "\n",
    "# modified_content = enclose_tags(clean_rtf_content)\n",
    "\n",
    "# Clean RTF content while preserving field codes\n",
    "\n",
    "# print(cleaned_rtf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c10a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = cleaned_rtf.split('\\n')\n",
    "print(lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabb2dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07169720",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_text= []\n",
    "line_count=0\n",
    "final_text_list = []\n",
    "for i, line in enumerate(lines[:10]):\n",
    "    # print(f\"Line {i}: {line.strip()}\")\n",
    "    if i == 0:\n",
    "        final_text_list.append(line.strip()) \n",
    "        final_text_list.append(\"<chapter>\")\n",
    "        continue\n",
    "    #append lines till not empty\n",
    "    if line.strip() == \"\":\n",
    "        final_text_list.append(line)\n",
    "        line_count+=1\n",
    "    else:\n",
    "        # If an empty line is encountered\n",
    "        #check if there is ch.rh is present within <field> tags\n",
    "        field = re.findall(r'<field>(.*?)</field>', line, re.DOTALL)[0]\n",
    "        print(f\"Field found: {field}\")\n",
    "        if 'ch.rh' in field:\n",
    "            metadata_value = field.split('ch.rh=')[1].split(' ')[0].replace('\"', '').replace(\"'\", \"\")\n",
    "            final_text_list.append(f\"<metadata.block><metadata field=\\\"right.running.head\\\"><value>{metadata_value}</value></metadata></metadata.block>\")\n",
    "            final_text_list.append(\"<front>\")\n",
    "            if \"Chapter\" in line:\n",
    "                remainder_line = line.split(\"Chapter\")[-1].strip().split(\" \")\n",
    "                final_text_list.append(f\"<outline.name.block><label>Chapter</label><designator>{remainder_line[0]}</designator><name>{remainder_line[1]}</name></outline.name.block><scope.statement.block>\")\n",
    "            else:\n",
    "                log_text.append(\"Chapter name might not be present\")\n",
    "            continue\n",
    "        if \"Scope Statement\" in line:\n",
    "            final_text_list.append(\"<scope.statement.block>\")\n",
    "            \n",
    "            final_text_list.append(\"</scope.statement.block>\")\n",
    "\n",
    "        \n",
    "        final_text_list.append(\"</front>\")\n",
    "\n",
    "final_text_list.append(\"</chapter>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9e5db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac88fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from lxml import etree\n",
    "\n",
    "import zipfile\n",
    "from lxml import etree\n",
    "\n",
    "def extract_full_text_with_breaks(docx_path):\n",
    "    # Open the .docx file as a zip archive\n",
    "    with zipfile.ZipFile(docx_path, 'r') as docx_zip:\n",
    "        # Read the document.xml file\n",
    "        xml_content = docx_zip.read('word/document.xml')\n",
    "        \n",
    "    # Parse the XML content\n",
    "    tree = etree.fromstring(xml_content)\n",
    "    \n",
    "    # Extract all text content, including field codes, and retain breaks\n",
    "    full_text = []\n",
    "    for elem in tree.iter():\n",
    "        # Add a newline for paragraph breaks\n",
    "        if elem.tag.endswith('p'):\n",
    "            full_text.append('\\n')\n",
    "        # Add text content\n",
    "        elif elem.tag.endswith('t'):\n",
    "                if elem.tag.endswith('instrText'):\n",
    "                    if elem.text:\n",
    "                        full_text.append(\"<field>\" + elem.text + '</field>')\n",
    "                else:\n",
    "                    if elem.text:\n",
    "                        full_text.append(elem.text)\n",
    "        # Add a newline for line breaks (often represented by <w:br>)\n",
    "        elif elem.tag.endswith('br'):\n",
    "            full_text.append('\\n')\n",
    "    \n",
    "    # Join all extracted text into a single string\n",
    "    return ''.join(full_text)\n",
    "# Usage\n",
    "docx_path = 'NYLB/doc_NYLB 32 (revision copy).docx'\n",
    "whole_text = extract_full_text_with_breaks(docx_path)\n",
    "\n",
    "# You can now use `raw_text` in another application or write it to a file\n",
    "with open('doc_iiioutput.txt', 'w', encoding=\"utf-8\") as f:\n",
    "    f.write(whole_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30265f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main execution starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47dda977",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_between_tags(text):\n",
    "    # Define the regular expression pattern\n",
    "    pattern = r'<field>(.*?)</field>'\n",
    "    \n",
    "    # Use re.findall to find all matches\n",
    "    matches = re.findall(pattern, text)\n",
    "    \n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_text_between_tags(text):\n",
    "    # Define the regular expression pattern to match the tags and the text between them\n",
    "    pattern = r'<field>.*?</field>'\n",
    "    \n",
    "    # Use re.sub to replace the matched text with an empty string\n",
    "    result = re.sub(pattern, '', text)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768bb4f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1cbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ending_treated(text):\n",
    "    # text_lines = text.split('\\n')\n",
    "    return_text = []\n",
    "    #save the lines until you find a line that starts with \"Research reference\"\n",
    "    for i,line in enumerate(text):\n",
    "        if line.lower().startswith(\"Research References\".lower()):\n",
    "            break\n",
    "        return_text.append(\"<para><para.text>\"+line.strip()+\"</para.text></para>\")\n",
    "    return return_text, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1a267f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_block_ending(text, opening_tag_name, closing_tag_name):\n",
    "    return_text = []\n",
    "    for i, line in enumerate(text):\n",
    "        if \"<field>\" not in line:\n",
    "            break\n",
    "        return_text.append(opening_tag_name+line.strip()+closing_tag_name)\n",
    "    return return_text, i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f19b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def merge_text(headings_list):\n",
    "#     # Initialize an empty list to store the result\n",
    "#     result = []\n",
    "#     target_text = \"Some text here\"  # The text to retain only the first occurrence of consecutive matches\n",
    "    \n",
    "#     # Initialize a flag to track consecutive matches\n",
    "#     previous_was_target = False\n",
    "    \n",
    "#     # Iterate over each element in the list\n",
    "#     for element in headings_list:\n",
    "#         if element == target_text:\n",
    "#             if not previous_was_target:\n",
    "#                 # Append the first occurrence of consecutive matches\n",
    "#                 result.append(element)\n",
    "#                 previous_was_target = True\n",
    "#         else:\n",
    "#             # Append non-matching elements\n",
    "#             result.append(element)\n",
    "#             previous_was_target = False\n",
    "    \n",
    "#     return result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45003df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_consecutive_text(input_dict):\n",
    "    cleaned_dict = {}\n",
    "    previous_value = None\n",
    "    target_text = \"Some text here\"\n",
    "    \n",
    "    for key, value in input_dict.items():\n",
    "        if value == target_text:\n",
    "            # If the current value matches the target string and is same as previous, skip adding it\n",
    "            if value == previous_value:\n",
    "                continue\n",
    "        # Add the current value to the cleaned dictionary\n",
    "        cleaned_dict[key] = value\n",
    "        # Update previous_value for next iteration\n",
    "        previous_value = value\n",
    "\n",
    "    return cleaned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d05089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_lines_without_field(lines):\n",
    "    # Initialize an empty dictionary to store the filtered lines with their indices\n",
    "    filtered_lines_dict = {}\n",
    "\n",
    "    # Iterate over each line with its index\n",
    "    for index, line in enumerate(lines):\n",
    "        if line.strip() != \"\":\n",
    "            # Check if the line does not contain the <field> tag\n",
    "            if ('<field>' not in line):\n",
    "                # Add the line to the dictionary with its index as the key\n",
    "                if '<>' not in line :\n",
    "                    filtered_lines_dict[index] = line\n",
    "                else:\n",
    "                    filtered_lines_dict[index] = \"Some text here\"\n",
    "            else:\n",
    "                filtered_lines_dict[index] = \"Some text here\"\n",
    "\n",
    "    return filtered_lines_dict\n",
    "\n",
    "\n",
    "index = 1\n",
    "result = filter_lines_without_field(lines[index:])\n",
    "#pretty print the result with indentation\n",
    "# llm_input = merge_text(result.values())\n",
    "# for i in llm_input:\n",
    "#     print(i)\n",
    "# for key, value in result.items():\n",
    "#     if value.strip():\n",
    "#         print(f\"Index: {key}, Value: {value}\")\n",
    "\n",
    "clean_values = merge_consecutive_text(result)\n",
    "for key, value in clean_values.items():\n",
    "    if value.strip():\n",
    "        #pretty print dictionary\n",
    "        print(f\"Index: {key}, Value: {value}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d52c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = whole_text.split('\\n')\n",
    "for i,line in enumerate(lines):\n",
    "    if \"<field>\" in line:\n",
    "        # print(i)\n",
    "        break\n",
    "\n",
    "#added first pheonix line\n",
    "xml_text = lines[i].split(\"</field>\")[-1].strip()\n",
    "\n",
    "#Chapter start\n",
    "xml_text += \"\\n<chapter>\"\n",
    "\n",
    "#Adding Metadata block\n",
    "metadata_text = extract_text_between_tags(lines[i+1])[0]\n",
    "if metadata_text.startswith(\"ch.rh\"):\n",
    "    metadata_value = metadata_text.split(\"=\")[1].replace('\"', '').replace(\"'\", \"\").strip()\n",
    "    xml_text += f\"\\n<metadata.block><metadata field=\\\"right.running.head\\\"><value>{metadata_value}</value></metadata></metadata.block>\"\n",
    "xml_text += \"\\n<front>\"\n",
    "\n",
    "\n",
    "# Adding outline name block\n",
    "if \"Chapter\".lower() in lines[i+1].lower():\n",
    "    remainder_line = lines[i+1].split(\"Chapter\")[-1].strip().split(\" \")\n",
    "    xml_text += f\"\\n<outline.name.block><label>Chapter</label><designator>{remainder_line[0]}</designator><name>{remainder_line[1]}</name></outline.name.block>\"\n",
    "    i += 1  # Skip the next line as it has been processed\n",
    "\n",
    "if \"Scope Statement\".lower() in lines[i+1].lower():\n",
    "    xml_text += \"\\n<scope.statement.block>\"\n",
    "    xml_text += f\"\\n<para><para.text>{lines[i+2]}</para.text></para>\"\n",
    "    xml_text += \"\\n</scope.statement.block>\"\n",
    "    i += 2  # Skip the next two lines as they have been processed\n",
    "\n",
    "if \"Treated Elsewhere\".lower() in lines[i+1].lower():\n",
    "    xml_text += \"\\n<treated.elsewhere.block>\"\n",
    "    treated_text, index = get_ending_treated(lines[i+2:])\n",
    "    index = i + 2 + index  # Adjust index to account for the lines processed\n",
    "    xml_text += f\"\\n<para><para.text>{(\"\\n\".join(treated_text))}</para.text></para>\"\n",
    "    xml_text += \"\\n</treated.elsewhere.block>\"\n",
    "    i += 2  # Skip the next two lines as they have been processed\n",
    "\n",
    "if line.strip().lower() == \"Research References\".lower():\n",
    "    xml_text += \"<research.reference.block>\"\n",
    "    reference_text, j = find_block_ending(lines[i+1],\"<reference.entry><ref.text>\",\"</ref.text></reference.entry>\")\n",
    "    xml_text += \"\\n\".join(reference_text)\n",
    "    xml_text += \"\\n</research.reference.block>\"\n",
    "    i += j+1 # Skip the next j lines as they have been processed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d580a34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e6212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#start for loop from index\n",
    "for i, line in enumerate(lines[index:]):\n",
    "    i += index\n",
    "    if line.strip().lower() == \"Research References\".lower():\n",
    "        xml_text += \"\\n<research.reference.block>\"\n",
    "        # print(f\"Processing Research References at line {i}: {line.strip()}\")\n",
    "        reference_text, j = find_block_ending(lines[i+1:],\"<reference.entry><ref.text>\",\"</ref.text></reference.entry>\")\n",
    "        # print(\"Reference text found:\", reference_text)\n",
    "        xml_text += \"\\n\".join(reference_text)\n",
    "        xml_text += \"\\n</research.reference.block>\"\n",
    "        i += j\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e5bfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xml_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "import re\n",
    "import xml.dom.minidom\n",
    "\n",
    "\n",
    "def preprocess_xml(xml_string):\n",
    "    # Replace the &dblsect; with a placeholder or remove it\n",
    "    # You can replace it with a space or any other character you prefer\n",
    "\n",
    "    # up_xml_string = re.sub(r'\\skey=\"[^\"]*\"', 'kkey', xml_string)\n",
    "    # up_xml_string = re.sub(r'&key;', '', xml_string)\n",
    "    # up_xml_string = re.sub(r'&dblsect;', '__dblsect__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&mdash;', '__mdash__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&ldquo;', '__ldquo__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&rdquo;', '__rdquo__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&sect;', '__sect__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&dblpara;', '__dblpara__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&dollar;', '__dollar__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&para;', '__para__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&percnt;', '__percnt__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&lsqb;', '__lsqb__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&rsqb;', '__rsqb__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&hellip;', '__hellip__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&brace;', '__brace__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&emsp;', '__emsp__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&ndash;', '__ndash__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&bull;', '__bull__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&ballot;', '__ballot__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&emsp;', '__emsp__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&ndash;', '__ndash__', up_xml_string)\n",
    "    # up_xml_string = re.sub(r'&bull;', '__bull__', up_xml_string)\n",
    "\n",
    "    up_xml_string = re.sub(r'&', '&amp;', xml_string)\n",
    "\n",
    "    return up_xml_string\n",
    "\n",
    "def pretty_print_xml(xml_string):\n",
    "    # Preprocess the XML to handle custom entities\n",
    "    cleaned_xml = preprocess_xml(xml_string)\n",
    "    \n",
    "    # # Parse the XML string\n",
    "    # parser = etree.XMLParser(resolve_entities=False)  # Disable entity resolution\n",
    "    # tree = etree.fromstring(cleaned_xml, parser=parser)\n",
    "    \n",
    "    # # Pretty print the XML\n",
    "    # pretty_xml = etree.tostring(tree, pretty_print=True, encoding='unicode')\n",
    "    # Parse the XML string\n",
    "    dom = xml.dom.minidom.parseString(cleaned_xml)\n",
    "    # Pretty print with indentation\n",
    "    pretty_xml_as_string = dom.toprettyxml(indent=\"  \")\n",
    "    # return pretty_xml_as_string\n",
    "    print(pretty_xml_as_string)\n",
    "    with open('pretty_output.xml', 'w', encoding='utf-8') as f:\n",
    "        f.write(pretty_xml_as_string)\n",
    "\n",
    "# Example XML string\n",
    "with open(r\"C:\\Users\\6122060\\Downloads\\231373p.xml\", 'r', encoding='utf-8') as file:\n",
    "    xml_string = file.read()\n",
    "\n",
    "pretty_print_xml(xml_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "407162bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ['►<field>p.ct.id=\"6d0bf250b92611ef8747b569df12a67d|7|32:7\"</field>The New York tax upon and with respect to personal income<footnote><footnote.body><f_break>1►<field>fn.fnref=\"1\"</field><f_break>►<field>p.ct.id=\"6d0bf250b92611ef8747b569df12a67d|7|32:7\"</field>See ►<field>st.ref.id=\"I05MHWY\"</field>NYTL &ss;§§601 et seq.<f_break></footnote.body></footnote> imposes a tax on the income of every resident individual of the state.<footnote><footnote.body><f_break>2►<field>fn.fnref=\"2\"</field><f_break>►<field>p.ct.id=\"6d0bf250b92611ef8747b569df12a67d|7|32:7\"</field>See ►<field>st.ref.id=\"I05JOS2\"</field>NYTL &s;§601.<f_break></footnote.body></footnote> The term &ldquo;“resident individual&rdquo;” applies only to natural persons. Partnerships, as such, are not subject to this tax.<footnote><footnote.body><f_break>3►<field>fn.fnref=\"3\"</field><f_break>►<field>p.ct.id=\"6d0bf250b92611ef8747b569df12a67d|7|32:7\"</field>See ►<field>st.ref.id=\"I05S46O\"</field>NYTL &s;§605.<trace> </trace><f_break><trace>For discussion of the federal tax provisions relating to agricultural cooperative associations, see </trace><field>x.ref.id=\"I047H79\"</field><trace>&ss;</trace><trace>§§</trace><trace>32:3 et seq.</trace><f_break>Research References<f_break>►<field>rc.ref.id=\"I05S46L\"</field>State income tax treatment of partnerships and partners, 2 ALR 6th 1.<f_break></footnote.body></footnote>', '<trace.deleted/>']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d1d7cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'►<field>p.ct.id=\"6d0bf250b92611ef8747b569df12a67d|7|32:7\"</field>The New York tax upon and with respect to personal income<footnote><footnote.body><f_break>1►<field>fn.fnref=\"1\"</field><f_break>►<field>p.ct.id=\"6d0bf250b92611ef8747b569df12a67d|7|32:7\"</field>See ►<field>st.ref.id=\"I05MHWY\"</field>NYTL &ss;§§601 et seq.<f_break></footnote.body></footnote> imposes a tax on the income of every resident individual of the state.<footnote><footnote.body><f_break>2►<field>fn.fnref=\"2\"</field><f_break>►<field>p.ct.id=\"6d0bf250b92611ef8747b569df12a67d|7|32:7\"</field>See ►<field>st.ref.id=\"I05JOS2\"</field>NYTL &s;§601.<f_break></footnote.body></footnote> The term &ldquo;“resident individual&rdquo;” applies only to natural persons. Partnerships, as such, are not subject to this tax.<footnote><footnote.body><f_break>3►<field>fn.fnref=\"3\"</field><f_break>►<field>p.ct.id=\"6d0bf250b92611ef8747b569df12a67d|7|32:7\"</field>See ►<field>st.ref.id=\"I05S46O\"</field>NYTL &s;§605.<trace> </trace><f_break><trace>For discussion of the federal tax provisions relating to agricultural cooperative associations, see </trace><field>x.ref.id=\"I047H79\"</field><trace>&ss;</trace><trace>§§</trace><trace>32:3 et seq.</trace><f_break>Research References<f_break>►<field>rc.ref.id=\"I05S46L\"</field>State income tax treatment of partnerships and partners, 2 ALR 6th 1.<f_break></footnote.body></footnote>'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5b1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks =[['i', 'ii', 'iii', 'iv', 'v', 'vi', 'vii', 'viii', 'ix', 'x', 'Service Information 1', 'Service Information 2', 'Service Information 3', 'Service Information 4', 'Service Information 5', 'Service Information 6', 'Service Information 7', 'Service Information 8', 'Service Information 9', 'Service Information 10'], ['Table of Cases 1', 'Table of Cases 2', 'Table of Cases 3', 'Table of Cases 4', 'Table of Cases 5', 'Table of Cases 6', 'Table of Cases 7', 'Table of Cases 8', 'Table of Cases 9', 'Table of Cases 10', 'Table of Cases 11', 'Table of Cases 12', 'Table of Cases 13', 'Table of Cases 14', 'Table of Cases 15', 'Table of Cases 16', 'Table of Cases 17', 'Table of Cases 18', 'Table of Cases 19', 'Table of Cases 20', 'Table of Cases 21', 'Table of Cases 22', 'Table of Cases 23', 'Table of Cases 24', 'Table of Cases 25', 'Table of Cases 26', 'Table of Cases 27', 'Table of Cases 28', 'Table of Cases 29', 'Table of Cases 30', 'Table of Cases 31', 'Table of Cases 32', 'Table of Cases 33', 'Table of Cases 34', 'Table of Cases 35', 'Table of Cases 36', 'Table of Cases 37', 'Table of Cases 38', 'Table of Cases 39', 'Table of Cases 40', 'Table of Cases 41', 'Table of Cases 42', 'Table of Cases 43', 'Table of Cases 44', 'Table of Cases 45', 'Table of Cases 46', 'Table of Cases 47', 'Table of Cases 48', 'Table of Cases 49', 'Table of Cases 50', 'Table of Cases 51', 'Table of Cases 52', 'Table of Cases 53', 'Table of Cases 54', 'Table of Cases 55', 'Table of Cases 56', 'Table of Cases 57', 'Table of Cases 58', 'Table of Cases 59', 'Table of Cases 60', 'Table of Cases 61', 'Table of Cases 62', 'Table of Cases 63', 'Table of Cases 64', 'Table of Cases 65', 'Table of Cases 66', 'Table of Cases 67', 'Table of Cases 68', 'Table of Cases 69', 'Table of Cases 70', 'Table of Cases 71', 'Table of Cases 72', 'Table of Cases 73', 'Table of Cases 74', 'Table of Cases 75', 'Table of Cases 76', 'Table of Cases 77', 'Table of Cases 78', 'Table of Cases 79', 'Table of Cases 80', 'Table of Cases 81', 'Table of Cases 82', 'Table of Cases 83', 'Table of Cases 84', 'Table of Cases 85', 'Table of Cases 86', 'Table of Cases 87', 'Table of Cases 88', 'Table of Cases 89', 'Table of Cases 90', 'Table of Cases 91', 'Table of Cases 92', 'Table of Cases 93', 'Table of Cases 94', 'Table of Cases 95', 'Table of Cases 96', 'Table of Cases 97', 'Table of Cases 98', 'Table of Cases 99', 'Table of Cases 100', 'Table of Cases 101', 'Table of Cases 102', 'Table of Cases 103', 'Table of Cases 104', 'Table of Cases 105', 'Table of Cases 106', 'Table of Cases 107', 'Table of Cases 108', 'Table of Cases 109', 'Table of Cases 110', 'Table of Cases 111', 'Table of Cases 112', 'Table of Cases 113', 'Table of Cases 114', 'Table of Cases 115', 'Table of Cases 116', 'Table of Cases 117', 'Table of Cases 118', 'Table of Cases 119', 'Table of Cases 120', 'Table of Cases 121', 'Table of Cases 122', 'Table of Cases 123', 'Table of Cases 124', 'Table of Statutes 1', 'Table of Statutes 2', 'Table of Statutes 3', 'Table of Statutes 4', 'Table of Statutes 5', 'Table of Statutes 6', 'Table of Statutes 7', 'Table of Statutes 8', 'Table of Statutes 9', 'Table of Statutes 10', 'Table of Statutes 11', 'Table of Statutes 12', 'Table of Statutes 13', 'Table of Statutes 14', 'Table of Statutes 15', 'Table of Statutes 16', 'Table of Statutes 17', 'Table of Statutes 18', 'Table of Statutes 19', 'Table of Statutes 20', 'Table of Statutes 21', 'Table of Statutes 22', 'Table of Statutes 23', 'Table of Statutes 24', 'Table of Statutes 25', 'Table of Statutes 26', 'Table of Statutes 27', 'Table of Statutes 28', 'Table of Statutes 29', 'Table of Statutes 30', 'Table of Statutes 31', 'Table of Statutes 32', 'Table of Statutes 33', 'Table of Statutes 34', 'Table of Statutes 35', 'Table of Statutes 36', 'Table of Statutes 37', 'Table of Statutes 38', 'Table of Statutory Instruments 1', 'Table of Statutory Instruments 2', 'Table of Statutory Instruments 3', 'Table of Statutory Instruments 4'], ['A1,130/3', 'A1,130/4'], ['A1,130/5'], ['A1,130/6'], ['A1,130/7'], ['A1,130/8'], ['A2,081', 'A2,082'], ['A2,082/1'], ['A2,082/2'], ['A2,082/3'], ['A2,082/4'], ['A4,023', 'A4,024'], ['A4,097', 'A4,098'], ['A4,098/1'], ['A4,098/2'], ['A4,132/1', 'A4,132/2', 'A4,132/3', 'A4,132/4'], ['A4,132/5'], ['A4,132/6'], ['A4,132/7'], ['A4,132/8'], ['A4,362/1', 'A4,362/2'], ['A4,391', 'A4,392'], ['A4,392/1'], ['A4,392/2'], ['A4,392/3'], ['A4,392/4'], ['A4,545', 'A4,546', 'A4,547', 'A4,548'], ['A4,549', 'A4,550', 'A4,550/1', 'A4,550/2', 'A4,550/3', 'A4,550/4'], ['A4,550/5'], ['A4,550/6'], ['A5,059', 'A5,060'], ['A5,060/1'], ['A5,060/2'], ['A5,060/3'], ['A5,060/4'], ['A5,060/5'], ['A5,060/6'], ['A5,060/7'], ['A5,060/8'], ['A6,061', 'A6,062', 'A6,063', 'A6,064', 'A6,065', 'A6,066', 'A6,067', 'A6,068', 'A6,069', 'A6,070', 'A6,071', 'A6,072', 'A6,073', 'A6,074'], ['A6,074/1'], ['A6,074/2'], ['A6,079', 'A6,080', 'A6,081', 'A6,082', 'A6,082/1', 'A6,082/2'], ['A6,147', 'A6,148'], ['A6,148/1'], ['A6,148/2'], ['A6,157', 'A6,158'], ['A8,099', 'A8,100', 'A8,101', 'A8,102', 'A8,103', 'A8,104', 'A8,105', 'A8,106', 'A8,107', 'A8,108', 'A8,109', 'A8,110', 'A8,111', 'A8,112', 'A8,113', 'A8,114', 'A8,115', 'A8,116', 'A8,117', 'A8,118', 'A8,119', 'A8,120', 'A8,121', 'A8,122', 'A8,123', 'A8,124', 'A8,125', 'A8,126', 'A8,127', 'A8,128', 'A8,129', 'A8,130', 'A8,131', 'A8,132', 'A8,133', 'A8,134', 'A8,135', 'A8,136', 'A8,137', 'A8,138', 'A8,139', 'A8,140', 'A8,141', 'A8,142', 'A8,143', 'A8,144', 'A8,145', 'A8,146', 'A8,147', 'A8,148'], ['A10,043', 'A10,044'], ['A10,044/1'], ['A10,044/2'], ['A10,044/3'], ['A10,044/4'], ['A10,044/5'], ['A10,044/6'], ['A10,044/7'], ['A10,044/8'], ['A10,044/9'], ['A10,044/10'], ['A10,049', 'A10,050'], ['A10,051', 'A10,052', 'A10,052/1', 'A10,052/2', 'A10,052/3', 'A10,052/4', 'A10,052/5', 'A10,052/6', 'A10,052/7', 'A10,052/8', 'A10,052/9', 'A10,052/10', 'A10,052/11', 'A10,052/12'], ['A10,052/13'], ['A10,052/14'], ['A10,115', 'A10,116'], ['A10,116/1'], ['A10,116/2'], ['A10,116/3'], ['A10,116/4'], ['A10,116/5'], ['A10,116/6'], ['B1,098/3', 'B1,098/4', 'B1,098/5', 'B1,098/6'], ['B1,098/7'], ['B1,098/8'], ['B1,120/2/1', 'B1,120/2/2', 'B1,120/2/3', 'B1,120/2/4', 'B1,120/2/5', 'B1,120/2/6'], ['B1,120/2/7'], ['B1,120/2/8'], ['B1,254/13', 'B1,254/14'], ['B1,254/15'], ['B1,254/16'], ['B1,345', 'B1,346'], ['B1,346/1'], ['B1,346/2'], ['B1,346/3'], ['B1,346/4'], ['B1,354/7', 'B1,354/8'], ['B1,404/1', 'B1,404/2'], ['B1,448/5', 'B1,448/6', 'B1,448/7', 'B1,448/8'], ['B1,448/9'], ['B1,448/10'], ['B1,459', 'B1,460', 'B1,460/1', 'B1,460/2', 'B1,460/3', 'B1,460/4'], ['B1,460/5'], ['B1,460/6'], ['B1,460/7'], ['B1,460/8'], ['B2,006/1', 'B2,006/2', 'B2,006/3', 'B2,006/4', 'B2,006/5', 'B2,006/6', 'B2,006/7', 'B2,006/8', 'B2,006/9', 'B2,006/10'], ['B2,006/11'], ['B2,006/12'], ['B2,014/2/9', 'B2,014/2/10', 'B2,014/2/11', 'B2,014/2/12', 'B2,014/2/13', 'B2,014/2/14', 'B2,014/2/15', 'B2,014/2/16', 'B2,014/2/17', 'B2,014/2/18', 'B2,014/2/19', 'B2,014/2/20', 'B2,014/2/21', 'B2,014/2/22', 'B2,014/2/23', 'B2,014/2/24'], ['B3,002/5', 'B3,002/6', 'B3,002/7', 'B3,002/8', 'B3,002/9', 'B3,002/10', 'B3,002/11', 'B3,002/12', 'B3,002/13', 'B3,002/14'], ['B3,002/15'], ['B3,002/16'], ['B3,009', 'B3,010'], ['B3,010/1'], ['B3,010/2'], ['B4,028/9', 'B4,028/10'], ['B4,028/11'], ['B4,028/12'], ['B6,036/1', 'B6,036/2', 'B6,036/3', 'B6,036/4', 'B6,036/5', 'B6,036/6', 'B6,036/7', 'B6,036/8'], ['B6,036/9'], ['B6,036/10'], ['B6,036/11'], ['B6,036/12'], ['B6,091', 'B6,092'], ['B6,092/1'], ['B6,092/2'], ['B6,092/3'], ['B6,092/4'], ['Index 1', 'Index 2', 'Index 3', 'Index 4', 'Index 5', 'Index 6', 'Index 7', 'Index 8', 'Index 9', 'Index 10', 'Index 11', 'Index 12', 'Index 13', 'Index 14', 'Index 15', 'Index 16', 'Index 17', 'Index 18', 'Index 19', 'Index 20', 'Index 21', 'Index 22', 'Index 23', 'Index 24', 'Index 25', 'Index 26', 'Index 27', 'Index 28', 'Index 29', 'Index 30', 'Index 31', 'Index 32', 'Index 33', 'Index 34', 'Index 35', 'Index 36', 'Index 37', 'Index 38', 'Index 39', 'Index 40', 'Index 41', 'Index 42', 'Index 43', 'Index 44', 'Index 45', 'Index 46', 'Index 47', 'Index 48', 'Index 49', 'Index 50', 'Index 51', 'Index 52', 'Index 53', 'Index 54', 'Index 55', 'Index 56', 'Index 57', 'Index 58', 'Index 59', 'Index 60', 'Index 61', 'Index 62', 'Index 63', 'Index 64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78731e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "start_self = [\n",
    "    'i', 'Service Information 1', 'Table of Cases 1', 'Table of Statutes 1', 'Table of Statutory Instruments 1',\n",
    "    'A1,130/3', '', '', '', '', 'A2,081', '', '', '', '', 'A4,023', 'A4,097', '', '', 'A4,132/1', '', '', '', '', 'A4,362/1',\n",
    "    'A4,391', '', '', '', '', 'A4,545', 'A4,549', '', '', 'A5,059', '', '', '', '', '', '', '', '', 'A6,061', '', '', 'A6,079',\n",
    "    'A6,147', '', '', 'A6,157', 'A8,099', 'A10,043', '', '', '', '', '', '', '', '', '', '', 'A10,049', 'A10,051', '', '', \n",
    "    'A10,115', '', '', '', '', '', '', 'B1,098/3', '', '', 'B1,120/2/1', '', '', 'B1,254/13', '', '', 'B1,345', '', '', '', '', \n",
    "    'B1,354/7', 'B1,404/1', 'B1,448/5', '', '', 'B1,459', '', '', '', '', 'B2,006/1', '', '', 'B2,014/2/9', 'B3,002/5', '', '', \n",
    "    'B3,009', '', '', 'B4,028/9', '', '', 'B6,036/1', '', '', '', '', 'B6,091', '', '', '', '', 'Index 1'\n",
    "]\n",
    "\n",
    "start = [\n",
    "    'i', 'Service Information 1', 'Table of Cases 1', 'Table of Statutes 1', 'Table of Statutory Instruments 1',\n",
    "    'A1,130/3', 'A1,130/5', 'A1,130/6', 'A1,130/7', 'A1,130/8', 'A2,081', 'A2,082/1', 'A2,082/2', 'A2,082/3', 'A2,082/4',\n",
    "    'A4,023', 'A4,097', 'A4,098/1', 'A4,098/2', 'A4,132/1', 'A4,132/5', 'A4,132/6', 'A4,132/7', 'A4,132/8', 'A4,362/1',\n",
    "    'A4,391', 'A4,392/1', 'A4,392/2', 'A4,392/3', 'A4,392/4', 'A4,545', 'A4,549', 'A4,550/5', 'A4,550/6', 'A5,059', 'A5,060/1',\n",
    "    'A5,060/2', 'A5,060/3', 'A5,060/4', 'A5,060/5', 'A5,060/6', 'A5,060/7', 'A5,060/8', 'A6,061', 'A6,074/1', 'A6,074/2',\n",
    "    'A6,079', 'A6,147', 'A6,148/1', 'A6,148/2', 'A6,157', 'A8,099', 'A10,043', 'A10,044/1', 'A10,044/2', 'A10,044/3',\n",
    "    'A10,044/4', 'A10,044/5', 'A10,044/6', 'A10,044/7', 'A10,044/8', 'A10,044/9', 'A10,044/10', 'A10,049', 'A10,051',\n",
    "    'A10,052/13', 'A10,052/14', 'A10,115', 'A10,116/1', 'A10,116/2', 'A10,116/3', 'A10,116/4', 'A10,116/5', 'A10,116/6',\n",
    "    'B1,098/3', 'B1,098/7', 'B1,098/8', 'B1,120/2/1', 'B1,120/2/7', 'B1,120/2/8', 'B1,254/13', 'B1,254/15', 'B1,254/16',\n",
    "    'B1,345', 'B1,346/1', 'B1,346/2', 'B1,346/3', 'B1,346/4', 'B1,354/7', 'B1,404/1', 'B1,448/5', 'B1,448/9', 'B1,448/10',\n",
    "    'B1,459', 'B1,460/5', 'B1,460/6', 'B1,460/7', 'B1,460/8', 'B2,006/1', 'B2,006/11', 'B2,006/12', 'B2,014/2/9', 'B3,002/5',\n",
    "    'B3,002/15', 'B3,002/16', 'B3,009', 'B3,010/1', 'B3,010/2', 'B4,028/9', 'B4,028/11', 'B4,028/12', 'B6,036/1', 'B6,036/9',\n",
    "    'B6,036/10', 'B6,036/11', 'B6,036/12', 'B6,091', 'B6,092/1', 'B6,092/2', 'B6,092/3', 'B6,092/4', 'Index 1'\n",
    "]\n",
    "\n",
    "mapping = defaultdict(list)\n",
    "last_key = None\n",
    "\n",
    "result = {}\n",
    "last_key = None\n",
    "\n",
    "for s_self, s in zip(start_self, start):\n",
    "    if s_self != '':\n",
    "        last_key = s_self\n",
    "    if last_key is not None:\n",
    "        result[last_key] = s\n",
    "    else:\n",
    "        # Edge case: if blanks at the start, you can skip or assign to a special key\n",
    "        result[''] = s\n",
    "\n",
    "# Print the mapping\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8332ab65",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_self = ['x', 'Service Information 10', 'Table of Cases 124', 'Table of Statutes 38', 'Table of Statutory Instruments 4', 'A1,130/4', '', '', '', '', 'A2,082', '', '', '', '', 'A4,024', 'A4,098', '', '', 'A4,132/4', '', '', '', '', 'A4,362/2', 'A4,392', '', '', '', '', 'A4,548', 'A4,550/4', '', '', 'A5,060', '', '', '', '', '', '', '', '', 'A6,074', '', '', 'A6,082/2', 'A6,148', '', '', 'A6,158', 'A8,148', 'A10,044', '', '', '', '', '', '', '', '', '', '', 'A10,050', 'A10,052/12', '', '', 'A10,116', '', '', '', '', '', '', 'B1,098/6', '', '', 'B1,120/2/6', '', '', 'B1,254/14', '', '', 'B1,346', '', '', '', '', 'B1,354/8', 'B1,404/2', 'B1,448/8', '', '', 'B1,460/4', '', '', '', '', 'B2,006/10', '', '', 'B2,014/2/24', 'B3,002/14', '', '', 'B3,010', '', '', 'B4,028/10', '', '', 'B6,036/8', '', '', '', '', 'B6,092', '', '', '', '', 'Index 64']\n",
    "end = ['x', 'Service Information 10', 'Table of Cases 124', 'Table of Statutes 38', 'Table of Statutory Instruments 4', 'A1,130/4', 'A1,130/5', 'A1,130/6', 'A1,130/7', 'A1,130/8', 'A2,082', 'A2,082/1', 'A2,082/2', 'A2,082/3', 'A2,082/4', 'A4,024', 'A4,098', 'A4,098/1', 'A4,098/2', 'A4,132/4', 'A4,132/5', 'A4,132/6', 'A4,132/7', 'A4,132/8', 'A4,362/2', 'A4,392', 'A4,392/1', 'A4,392/2', 'A4,392/3', 'A4,392/4', 'A4,548', 'A4,550/4', 'A4,550/5', 'A4,550/6', 'A5,060', 'A5,060/1', 'A5,060/2', 'A5,060/3', 'A5,060/4', 'A5,060/5', 'A5,060/6', 'A5,060/7', 'A5,060/8', 'A6,074', 'A6,074/1', 'A6,074/2', 'A6,082/2', 'A6,148', 'A6,148/1', 'A6,148/2', 'A6,158', 'A8,148', 'A10,044', 'A10,044/1', 'A10,044/2', 'A10,044/3', 'A10,044/4', 'A10,044/5', 'A10,044/6', 'A10,044/7', 'A10,044/8', 'A10,044/9', 'A10,044/10', 'A10,050', 'A10,052/12', 'A10,052/13', 'A10,052/14', 'A10,116', 'A10,116/1', 'A10,116/2', 'A10,116/3', 'A10,116/4', 'A10,116/5', 'A10,116/6', 'B1,098/6', 'B1,098/7', 'B1,098/8', 'B1,120/2/6', 'B1,120/2/7', 'B1,120/2/8', 'B1,254/14', 'B1,254/15', 'B1,254/16', 'B1,346', 'B1,346/1', 'B1,346/2', 'B1,346/3', 'B1,346/4', 'B1,354/8', 'B1,404/2', 'B1,448/8', 'B1,448/9', 'B1,448/10', 'B1,460/4', 'B1,460/5', 'B1,460/6', 'B1,460/7', 'B1,460/8', 'B2,006/10', 'B2,006/11', 'B2,006/12', 'B2,014/2/24', 'B3,002/14', 'B3,002/15', 'B3,002/16', 'B3,010', 'B3,010/1', 'B3,010/2', 'B4,028/10', 'B4,028/11', 'B4,028/12', 'B6,036/8', 'B6,036/9', 'B6,036/10', 'B6,036/11', 'B6,036/12', 'B6,092', 'B6,092/1', 'B6,092/2', 'B6,092/3', 'B6,092/4', 'Index 64']\n",
    "\n",
    "result = {}\n",
    "last_key = None\n",
    "\n",
    "for s_self, s in zip(end_self, end):\n",
    "    if s_self != '':\n",
    "        last_key = s_self\n",
    "    if last_key is not None:\n",
    "        e_result[last_key] = s\n",
    "    else:\n",
    "        # Edge case: if blanks at the start, you can skip or assign to a special key\n",
    "        e_result[''] = s\n",
    "\n",
    "# Print the resulting mapping\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9826152e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks =  [['nan'], ['nan'], ['iii', 'iv', 'v', 'vi', 'vii', 'viii'], ['Service Information 1', 'Service Information 2', 'Service Information 3', 'Service Information 4', 'Service Information 5', 'Service Information 6'], ['Table of Cases 1', 'Table of Cases 2', 'Table of Cases 3', 'Table of Cases 4', 'Table of Cases 5', 'Table of Cases 6', 'Table of Cases 7', 'Table of Cases 8', 'Table of Cases 9', 'Table of Cases 10', 'Table of Cases 11', 'Table of Cases 12', 'Table of Cases 13', 'Table of Cases 14', 'Table of Cases 15', 'Table of Cases 16', 'Table of Cases 17', 'Table of Cases 18', 'Table of Cases 19', 'Table of Cases 20', 'Table of Cases 21', 'Table of Cases 22', 'Table of Cases 23', 'Table of Cases 24', 'Table of Cases 25', 'Table of Cases 26', 'Table of Cases 27', 'Table of Cases 28', 'Table of Cases 29', 'Table of Cases 30', 'Table of Cases 31', 'Table of Cases 32', 'Table of Cases 33', 'Table of Cases 34', 'Table of Cases 35', 'Table of Cases 36', 'Table of Cases 37', 'Table of Cases 38', 'Table of Cases 39', 'Table of Cases 40', 'Table of Cases 41', 'Table of Cases 42', 'Table of Cases 43', 'Table of Cases 44', 'Table of Cases 45', 'Table of Cases 46', 'Table of Cases 47', 'Table of Cases 48', 'Table of Cases 49', 'Table of Cases 50', 'Table of Cases 51', 'Table of Cases 52', 'Table of Cases 53', 'Table of Cases 54', 'Table of Cases 55', 'Table of Cases 56', 'Table of Cases 57', 'Table of Cases 58', 'Table of Cases 59', 'Table of Cases 60', 'Table of Cases 61', 'Table of Cases 62', 'Table of Cases 63', 'Table of Cases 64', 'Table of Cases 65', 'Table of Cases 66', 'Table of Cases 67', 'Table of Cases 68', 'Table of Cases 69', 'Table of Cases 70', 'Table of Cases 71', 'Table of Cases 72', 'Table of Cases 73', 'Table of Cases 74', 'Table of Cases 75', 'Table of Cases 76', 'Table of Cases 77', 'Table of Cases 78', 'Table of Cases 79', 'Table of Cases 80', 'Table of Cases 81', 'Table of Cases 82', 'Table of Cases 83', 'Table of Cases 84', 'Table of Cases 85', 'Table of Cases 86', 'Table of Cases 87', 'Table of Cases 88', 'Table of Cases 89', 'Table of Cases 90', 'Table of Cases 91', 'Table of Cases 92', 'Table of Cases 93', 'Table of Cases 94', 'Table of Cases 95', 'Table of Cases 96', 'Table of Cases 97', 'Table of Cases 98', 'Table of Cases 99', 'Table of Cases 100', 'Table of Cases 101', 'Table of Cases 102', 'Table of Cases 103', 'Table of Cases 104', 'Table of Cases 105', 'Table of Cases 106', 'Table of Cases 107', 'Table of Cases 108', 'Table of Cases 109', 'Table of Cases 110'], ['Table of Statutes 1', 'Table of Statutes 2', 'Table of Statutes 3', 'Table of Statutes 4', 'Table of Statutes 5', 'Table of Statutes 6', 'Table of Statutes 7', 'Table of Statutes 8', 'Table of Statutes 9', 'Table of Statutes 10', 'Table of Statutes 11', 'Table of Statutes 12', 'Table of Statutes 13', 'Table of Statutes 14', 'Table of Statutes 15', 'Table of Statutes 16', 'Table of Statutes 17', 'Table of Statutes 18', 'Table of Statutes 19', 'Table of Statutes 20', 'Table of Statutes 21', 'Table of Statutes 22', 'Table of Statutes 23', 'Table of Statutes 24', 'Table of Statutes 25', 'Table of Statutes 26', 'Table of Statutes 27', 'Table of Statutes 28', 'Table of Statutes 29', 'Table of Statutes 30', 'Table of Statutes 31', 'Table of Statutes 32', 'Table of Statutes 33', 'Table of Statutes 34', 'Table of Statutes 35', 'Table of Statutes 36', 'Table of Statutes 37', 'Table of Statutes 38', 'Table of Statutes 39', 'Table of Statutes 40', 'Table of Statutes 41', 'Table of Statutes 42', 'Table of Statutes 43', 'Table of Statutes 44', 'Table of Statutes 45', 'Table of Statutes 46', 'Table of Statutes 47', 'Table of Statutes 48', 'Table of Statutes 49', 'Table of Statutes 50'], ['Table of Statutory Instruments 1', 'Table of Statutory Instruments 2', 'Table of Statutory Instruments 3', 'Table of Statutory Instruments 4', 'Table of Statutory Instruments 5', 'Table of Statutory Instruments 6', 'Table of Statutory Instruments 7', 'Table of Statutory Instruments 8', 'Table of Statutory Instruments 9', 'Table of Statutory Instruments 10'], ['331', '332', '333', '334', '335', '336', '337', '338', '338/1', '338/2'], ['342/7', '342/8', '342/9', '342/10', '342/11', '342/12', '342/13', '342/14', '342/15', '342/16', '342/17', '342/18', '342/19', '342/20', '342/21', '342/22', '342/23', '342/24'], ['342/25'], ['342/26'], ['342/27'], ['342/28'], ['342/29'], ['342/30'], ['363', '364', '365', '366', '366/1', '366/2', '366/2/1', '366/2/2'], ['421', '422', '422/1', '422/2', '422/2/1', '422/2/2'], ['467', '468'], ['501', '502'], ['503', '504', '505', '506', '506/1', '506/2', '506/2/1', '506/2/2'], ['513', '514', '515', '516', '517', '518'], ['525', '526'], ['539', '540'], ['576/1', '576/2', '576/3', '576/4', '576/4/1', '576/4/2'], ['[TOC App-1]'], ['[TOC App-2]'], ['729', '730'], ['765', '766', '767', '768'], ['802/9', '802/10'], ['802/11'], ['802/12'], ['802/13'], ['802/14'], ['1027', '1028', '1029', '1030', '1031', '1032', '1033', '1034', '1035', '1036', '1037', '1038', '1039', '1040', '1041', '1042', '1043', '1044', '1045', '1046', '1047', '1048', '1049', '1050', '1051', '1052'], ['1053'], ['1054'], ['1055'], ['1056'], ['1057'], ['1058'], ['1059'], ['1060'], ['1061'], ['1062'], ['Index 1', 'Index 2', 'Index 3', 'Index 4', 'Index 5', 'Index 6', 'Index 7', 'Index 8', 'Index 9', 'Index 10', 'Index 11', 'Index 12', 'Index 13', 'Index 14', 'Index 15', 'Index 16', 'Index 17', 'Index 18', 'Index 19', 'Index 20', 'Index 21', 'Index 22', 'Index 23', 'Index 24', 'Index 25', 'Index 26', 'Index 27', 'Index 28', 'Index 29', 'Index 30', 'Index 31', 'Index 32', 'Index 33', 'Index 34', 'Index 35', 'Index 36', 'Index 37', 'Index 38', 'Index 39', 'Index 40', 'Index 41', 'Index 42', 'Index 43', 'Index 44', 'Index 45', 'Index 46', 'Index 47', 'Index 48', 'Index 49', 'Index 50', 'Index 51', 'Index 52', 'Index 53', 'Index 54', 'Index 55', 'Index 56', 'Index 57', 'Index 58', 'Index 59', 'Index 60', 'Index 61', 'Index 62', 'Index 63', 'Index 64', 'Index 65', 'Index 66', 'Index 67', 'Index 68', 'Index 69', 'Index 70', 'Index 71', 'Index 72', 'Index 73', 'Index 74', 'Index 75', 'Index 76', 'Index 77', 'Index 78', 'Index 79', 'Index 80', 'Index 81', 'Index 82', 'Index 83', 'Index 84', 'Index 85', 'Index 86']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c043f1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Block:\n",
      "  - nan\n",
      "\n",
      "Block:\n",
      "  - nan\n",
      "\n",
      "Block:\n",
      "  - iii\n",
      "  - iv\n",
      "  - v\n",
      "  - vi\n",
      "  - vii\n",
      "  - viii\n",
      "\n",
      "Block:\n",
      "  - Service Information 1\n",
      "  - Service Information 2\n",
      "  - Service Information 3\n",
      "  - Service Information 4\n",
      "  - Service Information 5\n",
      "  - Service Information 6\n",
      "\n",
      "Block:\n",
      "  - Table of Cases 1\n",
      "  - Table of Cases 2\n",
      "  - Table of Cases 3\n",
      "  - Table of Cases 4\n",
      "  - Table of Cases 5\n",
      "  - Table of Cases 6\n",
      "  - Table of Cases 7\n",
      "  - Table of Cases 8\n",
      "  - Table of Cases 9\n",
      "  - Table of Cases 10\n",
      "  - Table of Cases 11\n",
      "  - Table of Cases 12\n",
      "  - Table of Cases 13\n",
      "  - Table of Cases 14\n",
      "  - Table of Cases 15\n",
      "  - Table of Cases 16\n",
      "  - Table of Cases 17\n",
      "  - Table of Cases 18\n",
      "  - Table of Cases 19\n",
      "  - Table of Cases 20\n",
      "  - Table of Cases 21\n",
      "  - Table of Cases 22\n",
      "  - Table of Cases 23\n",
      "  - Table of Cases 24\n",
      "  - Table of Cases 25\n",
      "  - Table of Cases 26\n",
      "  - Table of Cases 27\n",
      "  - Table of Cases 28\n",
      "  - Table of Cases 29\n",
      "  - Table of Cases 30\n",
      "  - Table of Cases 31\n",
      "  - Table of Cases 32\n",
      "  - Table of Cases 33\n",
      "  - Table of Cases 34\n",
      "  - Table of Cases 35\n",
      "  - Table of Cases 36\n",
      "  - Table of Cases 37\n",
      "  - Table of Cases 38\n",
      "  - Table of Cases 39\n",
      "  - Table of Cases 40\n",
      "  - Table of Cases 41\n",
      "  - Table of Cases 42\n",
      "  - Table of Cases 43\n",
      "  - Table of Cases 44\n",
      "  - Table of Cases 45\n",
      "  - Table of Cases 46\n",
      "  - Table of Cases 47\n",
      "  - Table of Cases 48\n",
      "  - Table of Cases 49\n",
      "  - Table of Cases 50\n",
      "  - Table of Cases 51\n",
      "  - Table of Cases 52\n",
      "  - Table of Cases 53\n",
      "  - Table of Cases 54\n",
      "  - Table of Cases 55\n",
      "  - Table of Cases 56\n",
      "  - Table of Cases 57\n",
      "  - Table of Cases 58\n",
      "  - Table of Cases 59\n",
      "  - Table of Cases 60\n",
      "  - Table of Cases 61\n",
      "  - Table of Cases 62\n",
      "  - Table of Cases 63\n",
      "  - Table of Cases 64\n",
      "  - Table of Cases 65\n",
      "  - Table of Cases 66\n",
      "  - Table of Cases 67\n",
      "  - Table of Cases 68\n",
      "  - Table of Cases 69\n",
      "  - Table of Cases 70\n",
      "  - Table of Cases 71\n",
      "  - Table of Cases 72\n",
      "  - Table of Cases 73\n",
      "  - Table of Cases 74\n",
      "  - Table of Cases 75\n",
      "  - Table of Cases 76\n",
      "  - Table of Cases 77\n",
      "  - Table of Cases 78\n",
      "  - Table of Cases 79\n",
      "  - Table of Cases 80\n",
      "  - Table of Cases 81\n",
      "  - Table of Cases 82\n",
      "  - Table of Cases 83\n",
      "  - Table of Cases 84\n",
      "  - Table of Cases 85\n",
      "  - Table of Cases 86\n",
      "  - Table of Cases 87\n",
      "  - Table of Cases 88\n",
      "  - Table of Cases 89\n",
      "  - Table of Cases 90\n",
      "  - Table of Cases 91\n",
      "  - Table of Cases 92\n",
      "  - Table of Cases 93\n",
      "  - Table of Cases 94\n",
      "  - Table of Cases 95\n",
      "  - Table of Cases 96\n",
      "  - Table of Cases 97\n",
      "  - Table of Cases 98\n",
      "  - Table of Cases 99\n",
      "  - Table of Cases 100\n",
      "  - Table of Cases 101\n",
      "  - Table of Cases 102\n",
      "  - Table of Cases 103\n",
      "  - Table of Cases 104\n",
      "  - Table of Cases 105\n",
      "  - Table of Cases 106\n",
      "  - Table of Cases 107\n",
      "  - Table of Cases 108\n",
      "  - Table of Cases 109\n",
      "  - Table of Cases 110\n",
      "\n",
      "Block:\n",
      "  - Table of Statutes 1\n",
      "  - Table of Statutes 2\n",
      "  - Table of Statutes 3\n",
      "  - Table of Statutes 4\n",
      "  - Table of Statutes 5\n",
      "  - Table of Statutes 6\n",
      "  - Table of Statutes 7\n",
      "  - Table of Statutes 8\n",
      "  - Table of Statutes 9\n",
      "  - Table of Statutes 10\n",
      "  - Table of Statutes 11\n",
      "  - Table of Statutes 12\n",
      "  - Table of Statutes 13\n",
      "  - Table of Statutes 14\n",
      "  - Table of Statutes 15\n",
      "  - Table of Statutes 16\n",
      "  - Table of Statutes 17\n",
      "  - Table of Statutes 18\n",
      "  - Table of Statutes 19\n",
      "  - Table of Statutes 20\n",
      "  - Table of Statutes 21\n",
      "  - Table of Statutes 22\n",
      "  - Table of Statutes 23\n",
      "  - Table of Statutes 24\n",
      "  - Table of Statutes 25\n",
      "  - Table of Statutes 26\n",
      "  - Table of Statutes 27\n",
      "  - Table of Statutes 28\n",
      "  - Table of Statutes 29\n",
      "  - Table of Statutes 30\n",
      "  - Table of Statutes 31\n",
      "  - Table of Statutes 32\n",
      "  - Table of Statutes 33\n",
      "  - Table of Statutes 34\n",
      "  - Table of Statutes 35\n",
      "  - Table of Statutes 36\n",
      "  - Table of Statutes 37\n",
      "  - Table of Statutes 38\n",
      "  - Table of Statutes 39\n",
      "  - Table of Statutes 40\n",
      "  - Table of Statutes 41\n",
      "  - Table of Statutes 42\n",
      "  - Table of Statutes 43\n",
      "  - Table of Statutes 44\n",
      "  - Table of Statutes 45\n",
      "  - Table of Statutes 46\n",
      "  - Table of Statutes 47\n",
      "  - Table of Statutes 48\n",
      "  - Table of Statutes 49\n",
      "  - Table of Statutes 50\n",
      "\n",
      "Block:\n",
      "  - Table of Statutory Instruments 1\n",
      "  - Table of Statutory Instruments 2\n",
      "  - Table of Statutory Instruments 3\n",
      "  - Table of Statutory Instruments 4\n",
      "  - Table of Statutory Instruments 5\n",
      "  - Table of Statutory Instruments 6\n",
      "  - Table of Statutory Instruments 7\n",
      "  - Table of Statutory Instruments 8\n",
      "  - Table of Statutory Instruments 9\n",
      "  - Table of Statutory Instruments 10\n",
      "\n",
      "Block:\n",
      "  - 331\n",
      "  - 332\n",
      "  - 333\n",
      "  - 334\n",
      "  - 335\n",
      "  - 336\n",
      "  - 337\n",
      "  - 338\n",
      "  - 338/1\n",
      "  - 338/2\n",
      "\n",
      "Block:\n",
      "  - 342/7\n",
      "  - 342/8\n",
      "  - 342/9\n",
      "  - 342/10\n",
      "  - 342/11\n",
      "  - 342/12\n",
      "  - 342/13\n",
      "  - 342/14\n",
      "  - 342/15\n",
      "  - 342/16\n",
      "  - 342/17\n",
      "  - 342/18\n",
      "  - 342/19\n",
      "  - 342/20\n",
      "  - 342/21\n",
      "  - 342/22\n",
      "  - 342/23\n",
      "  - 342/24\n",
      "\n",
      "Block:\n",
      "  - 342/25\n",
      "\n",
      "Block:\n",
      "  - 342/26\n",
      "\n",
      "Block:\n",
      "  - 342/27\n",
      "\n",
      "Block:\n",
      "  - 342/28\n",
      "\n",
      "Block:\n",
      "  - 342/29\n",
      "\n",
      "Block:\n",
      "  - 342/30\n",
      "\n",
      "Block:\n",
      "  - 363\n",
      "  - 364\n",
      "  - 365\n",
      "  - 366\n",
      "  - 366/1\n",
      "  - 366/2\n",
      "  - 366/2/1\n",
      "  - 366/2/2\n",
      "\n",
      "Block:\n",
      "  - 421\n",
      "  - 422\n",
      "  - 422/1\n",
      "  - 422/2\n",
      "  - 422/2/1\n",
      "  - 422/2/2\n",
      "\n",
      "Block:\n",
      "  - 467\n",
      "  - 468\n",
      "\n",
      "Block:\n",
      "  - 501\n",
      "  - 502\n",
      "\n",
      "Block:\n",
      "  - 503\n",
      "  - 504\n",
      "  - 505\n",
      "  - 506\n",
      "  - 506/1\n",
      "  - 506/2\n",
      "  - 506/2/1\n",
      "  - 506/2/2\n",
      "\n",
      "Block:\n",
      "  - 513\n",
      "  - 514\n",
      "  - 515\n",
      "  - 516\n",
      "  - 517\n",
      "  - 518\n",
      "\n",
      "Block:\n",
      "  - 525\n",
      "  - 526\n",
      "\n",
      "Block:\n",
      "  - 539\n",
      "  - 540\n",
      "\n",
      "Block:\n",
      "  - 576/1\n",
      "  - 576/2\n",
      "  - 576/3\n",
      "  - 576/4\n",
      "  - 576/4/1\n",
      "  - 576/4/2\n",
      "\n",
      "Block:\n",
      "  - [TOC App-1]\n",
      "\n",
      "Block:\n",
      "  - [TOC App-2]\n",
      "\n",
      "Block:\n",
      "  - 729\n",
      "  - 730\n",
      "\n",
      "Block:\n",
      "  - 765\n",
      "  - 766\n",
      "  - 767\n",
      "  - 768\n",
      "\n",
      "Block:\n",
      "  - 802/9\n",
      "  - 802/10\n",
      "\n",
      "Block:\n",
      "  - 802/11\n",
      "\n",
      "Block:\n",
      "  - 802/12\n",
      "\n",
      "Block:\n",
      "  - 802/13\n",
      "\n",
      "Block:\n",
      "  - 802/14\n",
      "\n",
      "Block:\n",
      "  - 1027\n",
      "  - 1028\n",
      "  - 1029\n",
      "  - 1030\n",
      "  - 1031\n",
      "  - 1032\n",
      "  - 1033\n",
      "  - 1034\n",
      "  - 1035\n",
      "  - 1036\n",
      "  - 1037\n",
      "  - 1038\n",
      "  - 1039\n",
      "  - 1040\n",
      "  - 1041\n",
      "  - 1042\n",
      "  - 1043\n",
      "  - 1044\n",
      "  - 1045\n",
      "  - 1046\n",
      "  - 1047\n",
      "  - 1048\n",
      "  - 1049\n",
      "  - 1050\n",
      "  - 1051\n",
      "  - 1052\n",
      "\n",
      "Block:\n",
      "  - 1053\n",
      "\n",
      "Block:\n",
      "  - 1054\n",
      "\n",
      "Block:\n",
      "  - 1055\n",
      "\n",
      "Block:\n",
      "  - 1056\n",
      "\n",
      "Block:\n",
      "  - 1057\n",
      "\n",
      "Block:\n",
      "  - 1058\n",
      "\n",
      "Block:\n",
      "  - 1059\n",
      "\n",
      "Block:\n",
      "  - 1060\n",
      "\n",
      "Block:\n",
      "  - 1061\n",
      "\n",
      "Block:\n",
      "  - 1062\n",
      "\n",
      "Block:\n",
      "  - Index 1\n",
      "  - Index 2\n",
      "  - Index 3\n",
      "  - Index 4\n",
      "  - Index 5\n",
      "  - Index 6\n",
      "  - Index 7\n",
      "  - Index 8\n",
      "  - Index 9\n",
      "  - Index 10\n",
      "  - Index 11\n",
      "  - Index 12\n",
      "  - Index 13\n",
      "  - Index 14\n",
      "  - Index 15\n",
      "  - Index 16\n",
      "  - Index 17\n",
      "  - Index 18\n",
      "  - Index 19\n",
      "  - Index 20\n",
      "  - Index 21\n",
      "  - Index 22\n",
      "  - Index 23\n",
      "  - Index 24\n",
      "  - Index 25\n",
      "  - Index 26\n",
      "  - Index 27\n",
      "  - Index 28\n",
      "  - Index 29\n",
      "  - Index 30\n",
      "  - Index 31\n",
      "  - Index 32\n",
      "  - Index 33\n",
      "  - Index 34\n",
      "  - Index 35\n",
      "  - Index 36\n",
      "  - Index 37\n",
      "  - Index 38\n",
      "  - Index 39\n",
      "  - Index 40\n",
      "  - Index 41\n",
      "  - Index 42\n",
      "  - Index 43\n",
      "  - Index 44\n",
      "  - Index 45\n",
      "  - Index 46\n",
      "  - Index 47\n",
      "  - Index 48\n",
      "  - Index 49\n",
      "  - Index 50\n",
      "  - Index 51\n",
      "  - Index 52\n",
      "  - Index 53\n",
      "  - Index 54\n",
      "  - Index 55\n",
      "  - Index 56\n",
      "  - Index 57\n",
      "  - Index 58\n",
      "  - Index 59\n",
      "  - Index 60\n",
      "  - Index 61\n",
      "  - Index 62\n",
      "  - Index 63\n",
      "  - Index 64\n",
      "  - Index 65\n",
      "  - Index 66\n",
      "  - Index 67\n",
      "  - Index 68\n",
      "  - Index 69\n",
      "  - Index 70\n",
      "  - Index 71\n",
      "  - Index 72\n",
      "  - Index 73\n",
      "  - Index 74\n",
      "  - Index 75\n",
      "  - Index 76\n",
      "  - Index 77\n",
      "  - Index 78\n",
      "  - Index 79\n",
      "  - Index 80\n",
      "  - Index 81\n",
      "  - Index 82\n",
      "  - Index 83\n",
      "  - Index 84\n",
      "  - Index 85\n",
      "  - Index 86\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for block in blocks:\n",
    "    print(\"Block:\")\n",
    "    for item in block:\n",
    "        print(f\"  - {item}\")\n",
    "    print()  # Print a newline for better readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab1e21b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
